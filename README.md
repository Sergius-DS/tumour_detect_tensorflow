# Clasificaci√≥n de Im√°genes M√©dicas con ResNet50 üß†üî¨

Este repositorio documenta un proyecto para la clasificaci√≥n de im√°genes m√©dicas, distinguiendo entre im√°genes "Healthy" y con "Tumor". Se utiliza un modelo de Deep Learning basado en la arquitectura ResNet50, implementado con TensorFlow. El flujo de trabajo sigue una estructura clara desde la preparaci√≥n de los datos hasta la evaluaci√≥n del modelo.

Las imagenes utilizadas para el entrenamiento se encuentra en el siguiente repositorio de Kaggle:
https://www.kaggle.com/datasets/hghdhygf/brain-tumor-mri-image-dataset

Pueden visualizar como funciona nuestro clasificador en la siguiente p√°gina de Streamlit:<br>
https://tumordetectpytorch-mjjigzzap9ihnrgnarsncp.streamlit.app/


## üöÄ Estructura del Proyecto por Bloques

El proyecto se organiza en cuatro bloques funcionales principales:

### Bloque 1: **Configuraci√≥n Inicial y Carga de Datos** üìÇ
Esta fase establece el entorno b√°sico y carga el conjunto de datos de im√°genes.
- Se preparan las herramientas necesarias, siendo **TensorFlow** el framework principal para el modelado.
- Las im√°genes se cargan desde un sistema de archivos estructurado, donde las rutas y sus correspondientes etiquetas (ej. "Healthy", "Tumor") se organizan en un formato manejable, t√≠picamente un DataFrame de Pandas.

### Bloque 2: **Preprocesamiento y Generadores de Im√°genes** üñºÔ∏è‚û°Ô∏èüî¢
Antes del entrenamiento, los datos de im√°genes requieren una preparaci√≥n significativa:
- **Codificaci√≥n de Etiquetas**: Las etiquetas textuales de las clases se convierten a un formato num√©rico.
- **Manejo de Desbalance**: Se aplica sobremuestreo (ej. `RandomOverSampler`) **exclusivamente al conjunto de entrenamiento** para asegurar un aprendizaje equilibrado.
- **Divisi√≥n de Datos**: El dataset se divide en conjuntos de entrenamiento, validaci√≥n y prueba.
- **Generadores de Datos (`ImageDataGenerator`)**: Se configuran generadores para alimentar eficientemente al modelo:
    - Para el entrenamiento, se aplica **aumentaci√≥n de datos** (rotaciones, zoom, etc.) y el preprocesamiento espec√≠fico de ResNet.
    - Para validaci√≥n y prueba, solo se aplica el preprocesamiento de ResNet, sin aumentaci√≥n, para una evaluaci√≥n objetiva.

### Bloque 3: **Construcci√≥n y Entrenamiento del Modelo ResNet50** üß†üîß
Aqu√≠ se define la arquitectura del modelo de Transfer Learning y se lleva a cabo el proceso de entrenamiento:
- **Modelo Base ResNet50**: Se carga la arquitectura ResNet50 pre-entrenada, sin su capa clasificadora original.
- **Capas Personalizadas**: Se a√±aden capas superiores (ej. GlobalAveragePooling, Dropout, Dense con activaci√≥n sigmoide) para adaptar el modelo a la tarea de clasificaci√≥n binaria.
- **Entrenamiento en Dos Fases**:
    1.  **Entrenamiento del Clasificador**: Inicialmente, solo se entrenan las capas personalizadas nuevas, manteniendo congelado el modelo base ResNet50.
    2.  **Fine-Tuning**: Posteriormente, se descongela el modelo base ResNet50 (o parte de √©l) y se contin√∫a el entrenamiento de todo el modelo con una tasa de aprendizaje m√°s baja para un ajuste fino.
- **Callbacks**: Se utilizan `EarlyStopping`, `ModelCheckpoint` y `ReduceLROnPlateau` para gestionar el entrenamiento, guardar el mejor modelo y ajustar la tasa de aprendizaje din√°micamente.

### Bloque 4: **Evaluaci√≥n del Modelo y Visualizaci√≥n de Resultados** üìäüìà
Finalmente, se eval√∫a el rendimiento del modelo entrenado utilizando el conjunto de prueba:
- Se calculan m√©tricas clave como P√©rdida, Exactitud y AUC.
- Se generan visualizaciones para interpretar el rendimiento:
    - **Matriz de Confusi√≥n**.
    - **Reporte de Clasificaci√≥n** (precisi√≥n, recall, F1-score).
    - **Curva ROC**.
- Se grafica el **historial de entrenamiento** (p√©rdida y exactitud a lo largo de las √©pocas) para analizar el proceso de aprendizaje.

---
